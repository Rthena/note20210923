#  [Distributed locks with Redis](https://redis.io/topics/distlock)

## **安全和活跃性保证**

我们将要仅使用 3个属性对我们的设计进行建模，从我们的角度来看，这是有效使用分布式锁所需的最低保证。

1、安全属性：互斥。在任何时候，只有一个客户端持有锁。

2、活跃属性 A：无死锁。最终总是有可能获得锁，即使锁定资源客户端崩溃或被分区。

3、活跃属性 B：容错。只要大多数 Redis 节点都已启动，客户端就可以获取和释放锁。



## **为什么基于故障转移的实现是不够的**

为了了解我们想要改进的地方，让我们分析一下大多数基于 Redis 的分布式锁库的当前状态。

使用 Redis 锁定资源的最简单方式是在实例里创建一个 key。key 通常是带有存活时间的，使用 Redis 的 expires 特性，以便最终将其释放（属性2）。当客户端需要释放资源时，它会删除这个 key。                                                                                              表面上看，很有效，但有一个问题：这是一个单点故障架构，如果 Redis 主机宕机怎么办？。好吧， 让我们来添加一个副本，当主机不可用的时候。

这个模型有一个明显的竞争条件：

1. 客户端 A 从master获取锁。
2. master 把 key 传送到 replica 之前崩溃了
3. replica 晋升为 master
4. 客户端 B 获取了客户端 A已经持有同一资源的锁，违反了安全！

有时，在特殊情况下（例如在失败期间），多个客户端可以同时持有锁是完全没问题的。 如果是这种情况，您可以使用基于复制的解决方案。 否则，我们建议实施本文档中描述的解决方案。



## 单实例的正确实现方式

在尝试克服上述单实例设置的限制之前，让我们检查一下如何在这个简单的情况下正确地做到这一点，因为在不时出现竞争条件的应用程序中，这实际上是一个可行的解决方案，并且因为锁定 单个实例是我们将用于此处描述的分布式算法的基础。

用如下，方法获取锁

```
    SET resource_name my_random_value NX PX 30000
```

该命令仅在密钥不存在（NX 选项）时设置密钥，过期时间为 30000 毫秒（PX 选项）。 密钥设置为值“my_random_value”。 该值在所有客户端和所有锁定请求中必须是唯一的。

基本上，随机值用于以安全的方式释放锁，脚本告诉 Redis：仅当密钥存在并且存储在密钥中的值正是我期望的值时才删除它。 这是通过以下 Lua 脚本完成的：

```
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```

这对于避免删除由另一个客户端创建的锁很重要。例如，客户端可能获取锁，在某些操作中被阻塞超过锁有效时间（密钥将到期的时间），然后删除其他客户端已经获取的锁。仅使用 DEL 是不安全的，因为客户端可能会删除另一个客户端的锁。使用上面的脚本，每个锁都用一个随机字符串“签名”，因此只有当它仍然是试图删除它的客户端设置的锁时，才会删除它。

这个随机字符串应该是什么？我假设它是来自 /dev/urandom 的 20 个字节，但是你可以找到更便宜的方法来使它对你的任务足够独特。例如，一个安全的选择是用 /dev/urandom 为 RC4 做种子，并从中生成一个伪随机流。一个更简单的解决方案是使用 unix 时间和微秒分辨率的组合，将它与客户端 ID 连接，它不是那么安全，但可能适合大多数环境中的任务。

我们用作关键生存时间的时间，称为“锁有效时间”。它既是自动释放时间，也是客户端在另一个客户端可能能够再次获取锁之前执行所需操作的时间，而不会在技术上违反互斥保证，这仅限于给定的窗口从获得锁的那一刻起的时间。

所以现在我们有一个很好的方法来获取和释放锁。该系统推理由单个始终可用的实例组成的非分布式系统是安全的。让我们将这个概念扩展到我们没有这种保证的分布式系统。



## Redlock算法

在分布式算法版本中，我们假设我们有 N 个 Redis 主节点。这些节点完全是独立的，所以我们不适用备份机或任何其他隐式协调系统。我们已经描述了如何在单个实例中安全地获取和释放锁。我们理所当然地认为算法会在单个实例中使用这种方法来获取和释放锁。在我们的示例中，我们设置了 N=5，这是一个合理的值，因此我们需要在不同的物理机或虚拟机上运行 5 个 Redis 主节点，以确保它们以几乎独立的方式失败。

为了获得锁，客户端需要执行如下操作：

1. 获取当前的时间，以毫秒为单位。
2. 它尝试顺序获取所有 N 个实例中的锁，在所有实例中使用相同的键名和随机值。在第 2 步中，当在每个实例中设置锁时，客户端使用一个比总锁释放时间更小的超时时间来获取它。例如，如果自动释放时间为 10 秒，则超时可能在 ~ 5-10秒范围内。这可以防止客户端长时间处于阻塞状态，试图与已关闭的 Redis 节点通信： 如果实例不可用，我们应该尽快尝试与下一个实例通信。
3. 客户端通过从当前时间中减去步骤 1 中获得的时间戳来计算获取锁所用的时间。当且仅当客户端能够在大多数实例（N/2+1，至少 3 个）中获取锁，并且获取锁用的总时间少于锁的有效时间，则认为该锁已获取。
4. 如果获得了锁，则其有效时间被视为初始有效时间减去经过的时间，如步骤 3 中计算的那样。
5. 如果客户端由于某种原因获取锁失败（或者它无法锁定 N/2+1 个实例或有效时间为负）， 他将尝试解锁所有实例（即便某些Redis实例根本就没有加锁成功，防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁）。



## 算法是否异步

算法依赖于这样一个假设：虽然进程之间没有同步时钟，但每个进程的本地时间任然以大致相同的速率流动，与锁的自动释放时间相比误差很小。这个假设与现实世界的计算机非常相似：每台计算机都有一个本地时钟，我们通常可以依靠不同的计算机来实现很小的时钟漂移。

在这一点上我们需要更好地指定我们的互斥规则：只要持有锁的客户端会在锁的有效期（如步骤 3 中获得的）减去一些时间（仅仅几毫秒用于补偿进程之间的时钟漂移）内终止其工作，就可以保证。



## 失败时重试

当一个客户端无法获取锁时，它应该在随机延时后重试，以便打破，在同一个时间内，多个客户端尝试获得同一资源的锁的情况。此外，客户端在大多数 Redis 实例中尝试获取锁的速度越快，出现脑裂情况的窗口就越小（以及需要重新），所以理想情况下，客户端应该尝试使用多路复用将 **SET **命令同时发送到 N 个实例。

值得强调的是，对于未能获取大部分锁的客户端而已，尽快释放（部分）获取的锁是很重要的，这样就无需等待 key 到期才能再次获取锁（然而，如果发生网络分区并且客户端不再能与 Redis 实例通信， 则在等待 key 到期时需要损失可用性）



## 释放锁

释放锁很简单，只涉及在所有实例中释放锁，无论客户端是否相信它能够成功锁定给定的实例。



## 安全参数

算法安全吗？我们可以尝试了解在不同的场景下发生了什么。

开始之前我们先假设在大多数实例中，客户端都能获取锁。所以的实例都将会包含一个具有相同的存活时间的 key。然而这个 key 被设置在不同的时间，因此这些 keys 都将在不同的时间过期。如果第一个 key 被设置在最差的时间 T1（我们在联系第一台服务器之前采样的时间），并且最后的 key 被设置在最差的时间 T2（我们获得最后一台服务器的应答的时间），我们可以肯定，集合中第一个到期的 key 将至少存在 MIN_VALIDITY=TTL-(T2-T1)-CLOCK_DRIFT。所有其他密钥将在稍后到期，因此我们确信至少这次 key 将同时设置。

在这个时间内大多数 key 被设置，另一个客户端将无法获取锁，因为如果 N/2+1 个键已经存在，则 N/2+1 次 SET NX 操作将无法成功。 因此，如果获取了锁，则不可能同时重新获取它（违反互斥属性）。

但是，我们还希望确保多个客户端同时尝试获取锁不能同时成功。

如果客户端使用接近或大于锁最大有效时间（我们基本用于 SET 的 TTL）的时间锁定了大多数实例，它会认为锁无效并解锁实例，因此我们只需要考虑 客户端能够在小于有效时间的时间内锁定大多数实例的情况。 在这种情况下，对于上面已经表达的参数，对于 MIN_VALIDITY，没有客户端应该能够重新获取锁。 因此，只有当锁定多数的时间大于 TTL 时间时，多个客户端才能同时锁定 N/2+1 个实例（“时间”为第 2 步的结束），从而使锁定无效。

您是否能够提供正式的安全证明、指出现有的相似算法或找到错误？ 这将不胜感激。



## 活性参数
系统活性基于三个主要特征：

锁的自动释放（因为钥匙过期）：最终钥匙可以再次被锁定。
事实上，客户端通常会在没有获得锁时合作移除锁，或者当获得锁并且工作终止时，这使得我们可能不必等待密钥到期来重新获取锁锁。
事实上，当客户端需要重试锁时，它等待的时间比获取大多数锁所需的时间要长得多，以便在资源争用期间不太可能出现脑裂情况。
然而，我们在网络分区上支付了与 TTL 时间相等的可用性惩罚，所以如果有连续的分区，我们可以无限期地支付这个惩罚。每次客户端获取锁并在能够删除锁之前被分区时都会发生这种情况。

基本上，如果有无限连续的网络分区，系统可能会在无限长的时间内变得不可用。



## 性能、崩溃恢复和 fsync
许多使用 Redis 作为锁服务器的用户在获取和释放锁的延迟以及每秒可能执行的获取/释放操作数量方面都需要高性能。为了满足这个需求，与N个Redis服务器通话以减少延迟的策略肯定是多路复用（或穷人的多路复用，即将socket置于非阻塞模式，发送所有命令，并读取所有命令稍后，假设客户端和每个实例之间的RTT相似）。

然而，如果我们想要针对崩溃恢复系统模型，还有另一个关于持久性的考虑。

基本上要看到这里的问题，让我们假设我们配置 Redis 根本没有持久性。客户端在 5 个实例中的 3 个中获取锁。其中一个客户端能够获取到锁的实例被重启，此时对于同一资源又可以锁定3个实例，另一个客户端可以再次锁定它，违反了锁的排他性的安全属性。

如果我们启用 AOF 持久化，情况会有所改善。例如，我们可以通过发送 SHUTDOWN 并重新启动它来升级服务器。因为 Redis 过期是在语义上实现的，所以当服务器关闭时，实际上时间仍然在流逝，所以我们所有的要求都很好。然而，一切都很好，只要它是干净的关机。停电了怎么办？如果 Redis 配置为默认情况下每秒在磁盘上进行 fsync，则可能在重新启动后我们的密钥丢失。理论上，如果我们想在面对任何类型的实例重启时保证锁的安全，我们需要在持久化设置中启用 fsync=always 。这反过来将完全破坏与传统上用于以安全方式实现分布式锁的 CP 系统相同级别的性能。

然而，事情总比乍一看的样子要好。基本上只要实例在崩溃后重新启动时，算法安全性就保留下来，它不再参与任何当前活动的锁，因此，当实例重新启动时，当前活动的锁集都是通过锁定其他实例获得的这是重新加入系统。

为了保证这一点，我们只需要让一个实例在崩溃后不可用至少比我们使用的最大 TTL 多一点，即实例崩溃时存在的所有锁的密钥所需的时间，以失效并自动释放。

即使没有任何可用的 Redis 持久性，使用延迟重启基本上也可以实现安全性，但是请注意，这可能会转化为可用性损失。例如，如果大多数实例崩溃，系统将在 TTL 中全局不可用（这里全局意味着在此期间根本没有资源可锁定）。



## 使算法更可靠：扩展锁
如果客户端执行的工作由小步骤组成，则可以默认使用较小的锁有效时间，并扩展实现锁扩展机制的算法。 基本上客户端，如果在计算的中间，当锁有效性接近低值时，可以通过向所有扩展密钥的实例的 Lua 脚本发送一个 Lua 脚本来扩展锁，如果键存在并且它的值仍然是 获取锁时客户端分配的随机值。

如果客户端能够将锁扩展到大多数实例，并且在有效时间内（基本上使用的算法与获取锁时使用的算法非常相似），客户端应该只考虑重新获取锁。

然而，这在技术上不会改变算法，因此应该限制锁重新获取尝试的最大次数，否则会违反活性属性之一。

